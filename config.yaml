
# Aegis扫描器配置

browser:
  # 你将要启动的Chrome实例的远程调试端口。
  remote_debugging_port: 9222

browser_pool:
  # =================================================================
  # 浏览器池模式选择 - 重要决策！
  # =================================================================
  
  # 模式选项：'shared' 或 'standalone'
  mode: 'standalone'
  # ----------------------------------------------------------------
  # 🤔 如何选择？
  # ----------------------------------------------------------------
  # • 无感体验优先级高 → standalone
  # • 认证实时性要求极高 → shared （但会破坏无感）
  # • 生产环境部署 → standalone
  
  # 并行影子浏览器数量，决定同时可以测试多少个页面
  # 注意：standalone 模式下每个 context 都会创建独立的浏览器实例
  pool_size: 3
  
  # 认证同步设置（仅 standalone 模式生效）
  # 实时监听间隔（秒）- 更频繁的检查意味着更好的实时性但更高的CPU使用
  realtime_check_interval: 2
  # 定时同步间隔（秒）- 作为实时监听的备份机制
  periodic_sync_interval: 30

scanner_scope:
  # 重要：只有在此列表中的域名/IP才会被分析。
  # 支持主域名匹配，如填写 "ctf.show" 可匹配所有 "*.ctf.show" 子域名
  whitelist_domains: ["ctf.show","121.43.58.124","127.0.0.1"]

llm_service:
  # =================================================================
  # AI推理设置
  # =================================================================
  
  # 推理等级: 'high' (信息最全，最智能), 'medium' (平衡), 或 'low' (信息精简，速度最快)
  # 对于gpt-oss等推理较慢的模型，推荐使用 'medium' 或 'low'
  reasoning_level: 'high'

  # 使用与OpenAI兼容的本地/远程API服务（如 LM Studio 或 Ollama 的 OpenAI 兼容模式）。
  api_config:
    base_url: "http://localhost:1234/v1"
    model_name: "openai/gpt-oss-20b" # LM Studio中的模型名称
    api_key: "lm-studio"
    timeout: 500 # 20B模型可能需要较长推理时间，保持500秒超时

logging:
  # 用于存储与AI完整对话以供调试的文件。
  ai_dialogues_file: "./logs/ai_dialogues.jsonl"
